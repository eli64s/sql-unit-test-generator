{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sql/test_metric_loans.sql'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/k01101011/Documents/GitHub/sql-unit-test-generator/notebooks/generate_tests.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/k01101011/Documents/GitHub/sql-unit-test-generator/notebooks/generate_tests.ipynb#W0sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m PATH \u001b[39m=\u001b[39m root \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata/test_\u001b[39m\u001b[39m{\u001b[39;00mMETRIC_DS_NM\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/k01101011/Documents/GitHub/sql-unit-test-generator/notebooks/generate_tests.ipynb#W0sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m SQL_FILE \u001b[39m=\u001b[39m root \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msql/test_\u001b[39m\u001b[39m{\u001b[39;00mMETRIC_DS_NM\u001b[39m}\u001b[39;00m\u001b[39m.sql\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/k01101011/Documents/GitHub/sql-unit-test-generator/notebooks/generate_tests.ipynb#W0sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(SQL_FILE, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/k01101011/Documents/GitHub/sql-unit-test-generator/notebooks/generate_tests.ipynb#W0sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m     MODEL_SQL \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mread()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/k01101011/Documents/GitHub/sql-unit-test-generator/notebooks/generate_tests.ipynb#W0sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m TEST_ID \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msqlmesh_test_suite_id\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/miniconda3/envs/gx/lib/python3.10/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sql/test_metric_loans.sql'"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from typing import Any, Dict\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import sqlglot\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class DataUnitTest:\n",
    "\n",
    "    def __init__(self, path: str, model_name: str, model_sql: str):\n",
    "        self.path = path\n",
    "        self.model_name = model_name\n",
    "        self.model_sql = model_sql\n",
    "        self.df = self.fetch_test_dataset(self.path)\n",
    "\n",
    "    def fetch_test_dataset(self, path) -> pd.DataFrame:\n",
    "        try:\n",
    "            return pd.read_csv(path)\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error fetching test dataset: {e}\")\n",
    "\n",
    "    def extract_ctes_from_sql(self):\n",
    "        parsed = sqlglot.parse(self.model_sql)\n",
    "        statements = {}\n",
    "        for stmt in parsed:\n",
    "            try:\n",
    "                if stmt.ctes:\n",
    "                    cte_map = {}\n",
    "                    statements['CTE'] = str(stmt)\n",
    "                    for idx, cte in enumerate(stmt.ctes):\n",
    "        \n",
    "                        cte_str = str(cte)\n",
    "                        name = cte_str.split('AS')[0].strip()\n",
    "                        query = cte_str.split('AS', 1)[1].strip()\n",
    "                        query = sqlglot.transpile(query, write=\"duckdb\", identify=True, pretty=True)[0]\n",
    "                        cte_map[cte.alias] = query\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            if type(stmt).__name__ == 'Command':\n",
    "                stmt_type = type(stmt).expression\n",
    "                statements[str(stmt_type)] = stmt\n",
    "            else:\n",
    "                stmt_type = type(stmt).__name__\n",
    "                statements[str(stmt_type)] = stmt \n",
    "        return cte_map, statements\n",
    "\n",
    "    def fetch_cte_data(self, cte_map: Dict[str, str]) -> Dict[str, Any]:\n",
    "        sql_df = self.df.copy()\n",
    "        cte_data = {}\n",
    "        for cte_name, cte_query in cte_map.items():\n",
    "            try:\n",
    "                cte_query = cte_query.removesuffix(')').removeprefix('(').strip()\n",
    "                cte_query = cte_query.replace(\"loans\", \"sql_df\")\n",
    "                cte_df = duckdb.query(cte_query).fetch_arrow_table().to_pandas()\n",
    "                cte_data[cte_name] = cte_df.to_dict('records')\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error fetching CTE data for {cte_name}: {e}\")\n",
    "                raise\n",
    "        return cte_data\n",
    "\n",
    "    def generate_test_yaml(self) -> str:\n",
    "        ctes, statements = self.extract_ctes_from_sql()\n",
    "        test_structure = {\n",
    "            TEST_ID: {\n",
    "                \"model\": self.model_name,\n",
    "                \"inputs\": {\n",
    "                    INPUT_MODEL: {\n",
    "                        \"rows\": self.df.to_dict('records')\n",
    "                    }\n",
    "                },\n",
    "                \"outputs\": {\n",
    "                    \"query\": {},\n",
    "                    \"ctes\": {}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        cte_data = self.fetch_cte_data(ctes)\n",
    "        for cte_name, data in cte_data.items():\n",
    "            test_structure[TEST_ID][\"outputs\"][\"ctes\"][cte_name] = {\"rows\": data}\n",
    "    \n",
    "        try:\n",
    "            loans = self.df.copy()\n",
    "            main_query_output = duckdb.query(str(statements['CTE'])).fetch_arrow_table().to_pandas()\n",
    "            test_structure[TEST_ID][\"outputs\"][\"query\"][\"rows\"] = main_query_output.to_dict('records')\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in main query: {e}\")\n",
    "            raise\n",
    "    \n",
    "        return yaml.dump(test_structure)\n",
    "\n",
    "    def run(self) -> str:\n",
    "        return self.generate_test_yaml()\n",
    "\n",
    "\n",
    "def modify_yaml(file_path, data):\n",
    "    data = yaml.load(data, Loader=yaml.FullLoader)\n",
    "    model_value = data.get('model', None)\n",
    "    if TEST_ID in data and 'inputs' in data[TEST_ID]:\n",
    "        data[TEST_ID] = {\n",
    "            'model': model_value,\n",
    "            **data[TEST_ID]\n",
    "        }\n",
    "    with open(file_path, 'w') as f:\n",
    "        yaml.dump(data, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    \n",
    "    root = Path().cwd().parent\n",
    "    METRIC_DS_NM = \"metric_loans\"\n",
    "    DATA_FILE = root / f\"data/test_{METRIC_DS_NM}.csv\"\n",
    "    OUTPUT_FILE = root / f\"tests/test_{METRIC_DS_NM}.yaml\"\n",
    "    SQL_FILE = root / f\"sql/test_{METRIC_DS_NM}.sql\"\n",
    "    with open(SQL_FILE, 'r') as file:\n",
    "        MODEL_SQL = file.read()\n",
    "\n",
    "    TEST_ID = f\"sqlmesh_test_suite_id\"\n",
    "    INPUT_MODEL = f\"sqlmesh_test_id.{METRIC_DS_NM}_input_model\"\n",
    "    MODEL_NM = f\"sqlmesh_test_id.{METRIC_DS_NM}_full_model\"\n",
    "\n",
    "    tester = DataUnitTest(DATA_FILE, MODEL_NM, MODEL_SQL)\n",
    "    yaml_output = tester.run()\n",
    "    modify_yaml(OUTPUT_FILE, yaml_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   loan_id     applicant_name  applicant_age  loan_amount  loan_duration  \\\n",
      "0        1        Taylor Ball             39       924966             52   \n",
      "1        2   Vanessa Anderson             35       908595             54   \n",
      "2        3  Christopher White             25       947483             49   \n",
      "3        4       Kayla Golden             32       670765             52   \n",
      "4        5  Haley Fitzpatrick             37       841284             19   \n",
      "\n",
      "   interest_rate application_date loan_type  \n",
      "0           8.45       2022-04-02      Auto  \n",
      "1          11.75       2023-06-17  Personal  \n",
      "2           8.19       2022-08-07      Auto  \n",
      "3           7.65       2021-03-04      Auto  \n",
      "4           3.94       2020-12-12      Auto  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "\n",
    "# Initialize faker\n",
    "fake = Faker()\n",
    "\n",
    "# Number of rows\n",
    "num_rows = 1000\n",
    "\n",
    "# Generate the data\n",
    "data = {\n",
    "    'loan_id': range(1, num_rows + 1),\n",
    "    'applicant_name': [fake.name() for _ in range(num_rows)],\n",
    "    'applicant_age': [fake.random_int(min=20, max=60) for _ in range(num_rows)],\n",
    "    'loan_amount': [fake.random_number(digits=6) for _ in range(num_rows)],\n",
    "    'loan_duration': [fake.random_int(min=12, max=60) for _ in range(num_rows)],  # 12 to 60 months\n",
    "    'interest_rate': [fake.pyfloat(left_digits=2, right_digits=2, positive=True, min_value=2.0, max_value=15.0) for _ in range(num_rows)],  # 2% to 15%\n",
    "    'application_date': [fake.date_this_decade() for _ in range(num_rows)],\n",
    "    'loan_type': [fake.random_element(elements=('Home', 'Auto', 'Personal')) for _ in range(num_rows)]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_loans = pd.DataFrame(data)\n",
    "\n",
    "# Display a sample of the data\n",
    "print(df_loans.head())\n",
    "df_loans.to_csv('loans_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
